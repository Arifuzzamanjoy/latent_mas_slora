23:32:22  INFO      src.evaluation.ablation  ============================================================
23:32:22  INFO      src.evaluation.ablation  Setting up config: A_single_model
23:32:22  INFO      src.evaluation.ablation  ============================================================
23:32:22  INFO      src.evaluation.ablation  Loading base model: Qwen/Qwen2.5-7B-Instruct
23:32:22  INFO      httpx  HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
23:32:23  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen2.5-7B-Instruct/a09a35458c702b33eeacc393d103063234e8bc28/config.json "HTTP/1.1 200 OK"
23:32:23  INFO      httpx  HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
23:32:23  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen2.5-7B-Instruct/a09a35458c702b33eeacc393d103063234e8bc28/tokenizer_config.json "HTTP/1.1 200 OK"
23:32:23  INFO      httpx  HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-7B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
23:32:23  INFO      httpx  HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-7B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
23:32:24  INFO      httpx  HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-7B-Instruct "HTTP/1.1 200 OK"
23:32:24  INFO      httpx  HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
23:32:24  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen2.5-7B-Instruct/a09a35458c702b33eeacc393d103063234e8bc28/config.json "HTTP/1.1 200 OK"
`torch_dtype` is deprecated! Use `dtype` instead!
23:32:24  INFO      httpx  HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
23:32:24  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen2.5-7B-Instruct/a09a35458c702b33eeacc393d103063234e8bc28/config.json "HTTP/1.1 200 OK"
Loading weights:   0%|          | 0/339 [00:00<?, ?it/s]Loading weights:   0%|          | 1/339 [00:00<00:00, 3515.76it/s, Materializing param=lm_head.weight]Loading weights:   0%|          | 1/339 [00:00<00:00, 2305.83it/s, Materializing param=lm_head.weight]Loading weights:   1%|          | 2/339 [00:00<00:00, 1926.64it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 2/339 [00:00<00:00, 1733.54it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 3/339 [00:00<00:00, 1980.31it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   1%|          | 3/339 [00:00<00:00, 1855.07it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   1%|          | 4/339 [00:00<00:00, 1911.06it/s, Materializing param=model.layers.0.mlp.down_proj.weight]  Loading weights:   1%|          | 4/339 [00:00<00:00, 1779.89it/s, Materializing param=model.layers.0.mlp.down_proj.weight]Loading weights:   1%|▏         | 5/339 [00:00<00:00, 1932.15it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   1%|▏         | 5/339 [00:00<00:00, 1847.55it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   2%|▏         | 6/339 [00:00<00:00, 1946.61it/s, Materializing param=model.layers.0.mlp.up_proj.weight]  Loading weights:   2%|▏         | 6/339 [00:00<00:00, 1881.13it/s, Materializing param=model.layers.0.mlp.up_proj.weight]Loading weights:   2%|▏         | 7/339 [00:00<00:00, 2008.49it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   2%|▏         | 7/339 [00:00<00:00, 1952.14it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   2%|▏         | 8/339 [00:00<00:00, 1854.14it/s, Materializing param=model.layers.0.self_attn.k_proj.bias]          Loading weights:   2%|▏         | 8/339 [00:00<00:00, 1811.70it/s, Materializing param=model.layers.0.self_attn.k_proj.bias]Loading weights:   3%|▎         | 9/339 [00:00<00:00, 1895.11it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]Loading weights:   3%|▎         | 9/339 [00:00<00:00, 1829.80it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]Loading weights:   3%|▎         | 10/339 [00:00<00:00, 1906.42it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   3%|▎         | 10/339 [00:00<00:00, 1871.12it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   3%|▎         | 11/339 [00:00<00:00, 1950.34it/s, Materializing param=model.layers.0.self_attn.q_proj.bias]  Loading weights:   3%|▎         | 11/339 [00:00<00:00, 1914.33it/s, Materializing param=model.layers.0.self_attn.q_proj.bias]Loading weights:   4%|▎         | 12/339 [00:00<00:00, 1938.52it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   4%|▎         | 12/339 [00:00<00:00, 1903.62it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   4%|▍         | 13/339 [00:00<00:00, 1924.74it/s, Materializing param=model.layers.0.self_attn.v_proj.bias]  Loading weights:   4%|▍         | 13/339 [00:00<00:00, 1739.93it/s, Materializing param=model.layers.0.self_attn.v_proj.bias]Loading weights:   4%|▍         | 14/339 [00:00<00:00, 1824.40it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   4%|▍         | 14/339 [00:00<00:00, 1801.62it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   4%|▍         | 15/339 [00:00<00:00, 1833.71it/s, Materializing param=model.layers.1.input_layernorm.weight] Loading weights:   4%|▍         | 15/339 [00:00<00:00, 1740.09it/s, Materializing param=model.layers.1.input_layernorm.weight]Loading weights:   5%|▍         | 16/339 [00:00<00:00, 1771.99it/s, Materializing param=model.layers.1.mlp.down_proj.weight]  Loading weights:   5%|▍         | 16/339 [00:00<00:00, 1737.22it/s, Materializing param=model.layers.1.mlp.down_proj.weight]Loading weights:   5%|▌         | 17/339 [00:00<00:00, 1803.86it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   5%|▌         | 17/339 [00:00<00:00, 1785.21it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   5%|▌         | 18/339 [00:00<00:00, 1838.08it/s, Materializing param=model.layers.1.mlp.up_proj.weight]  Loading weights:   5%|▌         | 18/339 [00:00<00:00, 1820.58it/s, Materializing param=model.layers.1.mlp.up_proj.weight]Loading weights:   6%|▌         | 19/339 [00:00<00:00, 1859.13it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   6%|▌         | 19/339 [00:00<00:00, 1841.22it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   6%|▌         | 20/339 [00:00<00:00, 1861.69it/s, Materializing param=model.layers.1.self_attn.k_proj.bias]          Loading weights:   6%|▌         | 20/339 [00:00<00:00, 1844.26it/s, Materializing param=model.layers.1.self_attn.k_proj.bias]Loading weights:   6%|▌         | 21/339 [00:00<00:00, 1892.61it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]Loading weights:   6%|▌         | 21/339 [00:00<00:00, 1876.37it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]Loading weights:   6%|▋         | 22/339 [00:00<00:00, 1929.79it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   6%|▋         | 22/339 [00:00<00:00, 1914.33it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   7%|▋         | 23/339 [00:00<00:00, 1617.36it/s, Materializing param=model.layers.1.self_attn.q_proj.bias]  Loading weights:   7%|▋         | 23/339 [00:00<00:00, 1605.14it/s, Materializing param=model.layers.1.self_attn.q_proj.bias]Loading weights:   7%|▋         | 24/339 [00:00<00:00, 1610.61it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:   7%|▋         | 24/339 [00:00<00:00, 1593.81it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:   7%|▋         | 25/339 [00:00<00:00, 1599.46it/s, Materializing param=model.layers.1.self_attn.v_proj.bias]  Loading weights:   7%|▋         | 25/339 [00:00<00:00, 1583.21it/s, Materializing param=model.layers.1.self_attn.v_proj.bias]Loading weights:   8%|▊         | 26/339 [00:00<00:00, 1563.29it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:   8%|▊         | 26/339 [00:00<00:00, 1545.26it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:   8%|▊         | 27/339 [00:00<00:00, 1430.13it/s, Materializing param=model.layers.2.input_layernorm.weight] Loading weights:   8%|▊         | 27/339 [00:00<00:00, 1416.92it/s, Materializing param=model.layers.2.input_layernorm.weight]Loading weights:   8%|▊         | 28/339 [00:00<00:00, 1011.42it/s, Materializing param=model.layers.2.mlp.down_proj.weight]  Loading weights:   8%|▊         | 28/339 [00:00<00:00, 1004.33it/s, Materializing param=model.layers.2.mlp.down_proj.weight]Loading weights:   9%|▊         | 29/339 [00:00<00:00, 1017.37it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:   9%|▊         | 29/339 [00:00<00:00, 1009.84it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:   9%|▉         | 30/339 [00:00<00:00, 1012.16it/s, Materializing param=model.layers.2.mlp.up_proj.weight]  Loading weights:   9%|▉         | 30/339 [00:00<00:00, 1004.92it/s, Materializing param=model.layers.2.mlp.up_proj.weight]Loading weights:   9%|▉         | 31/339 [00:00<00:00, 1015.82it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:   9%|▉         | 31/339 [00:00<00:00, 1008.20it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:   9%|▉         | 32/339 [00:00<00:00, 1008.86it/s, Materializing param=model.layers.2.self_attn.k_proj.bias]          Loading weights:   9%|▉         | 32/339 [00:00<00:00, 1002.62it/s, Materializing param=model.layers.2.self_attn.k_proj.bias]Loading weights:  10%|▉         | 33/339 [00:00<00:00, 1017.75it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]Loading weights:  10%|▉         | 33/339 [00:00<00:00, 1012.88it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]Loading weights:  10%|█         | 34/339 [00:00<00:00, 1021.08it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  10%|█         | 34/339 [00:00<00:00, 1014.53it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  10%|█         | 35/339 [00:00<00:00, 1024.44it/s, Materializing param=model.layers.2.self_attn.q_proj.bias]  Loading weights:  10%|█         | 35/339 [00:00<00:00, 1018.13it/s, Materializing param=model.layers.2.self_attn.q_proj.bias]Loading weights:  11%|█         | 36/339 [00:00<00:00, 1027.81it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  11%|█         | 36/339 [00:00<00:00, 1021.60it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  11%|█         | 37/339 [00:00<00:00, 1018.48it/s, Materializing param=model.layers.2.self_attn.v_proj.bias]  Loading weights:  11%|█         | 37/339 [00:00<00:00, 1012.40it/s, Materializing param=model.layers.2.self_attn.v_proj.bias]Loading weights:  11%|█         | 38/339 [00:00<00:00, 1019.09it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  11%|█         | 38/339 [00:00<00:00, 1013.37it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  12%|█▏        | 39/339 [00:00<00:00, 1024.69it/s, Materializing param=model.layers.3.input_layernorm.weight] Loading weights:  12%|█▏        | 39/339 [00:00<00:00, 1018.77it/s, Materializing param=model.layers.3.input_layernorm.weight]Loading weights:  12%|█▏        | 40/339 [00:00<00:00, 1005.01it/s, Materializing param=model.layers.3.mlp.down_proj.weight]  Loading weights:  12%|█▏        | 40/339 [00:00<00:00, 999.68it/s, Materializing param=model.layers.3.mlp.down_proj.weight] Loading weights:  12%|█▏        | 41/339 [00:00<00:00, 1008.41it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  12%|█▏        | 41/339 [00:00<00:00, 1002.36it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  12%|█▏        | 42/339 [00:00<00:00, 1010.74it/s, Materializing param=model.layers.3.mlp.up_proj.weight]  Loading weights:  12%|█▏        | 42/339 [00:00<00:00, 1005.23it/s, Materializing param=model.layers.3.mlp.up_proj.weight]Loading weights:  13%|█▎        | 43/339 [00:00<00:00, 1012.15it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  13%|█▎        | 43/339 [00:00<00:00, 1006.66it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  13%|█▎        | 44/339 [00:00<00:00, 1019.84it/s, Materializing param=model.layers.3.self_attn.k_proj.bias]          Loading weights:  13%|█▎        | 44/339 [00:00<00:00, 1015.89it/s, Materializing param=model.layers.3.self_attn.k_proj.bias]Loading weights:  13%|█▎        | 45/339 [00:00<00:00, 1024.18it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]Loading weights:  13%|█▎        | 45/339 [00:00<00:00, 1019.26it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]Loading weights:  14%|█▎        | 46/339 [00:00<00:00, 1026.95it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  14%|█▎        | 46/339 [00:00<00:00, 1021.94it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  14%|█▍        | 47/339 [00:00<00:00, 1012.14it/s, Materializing param=model.layers.3.self_attn.q_proj.bias]  Loading weights:  14%|█▍        | 47/339 [00:00<00:00, 1006.85it/s, Materializing param=model.layers.3.self_attn.q_proj.bias]Loading weights:  14%|█▍        | 48/339 [00:00<00:00, 1013.37it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  14%|█▍        | 48/339 [00:00<00:00, 1008.84it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  14%|█▍        | 49/339 [00:00<00:00, 952.61it/s, Materializing param=model.layers.3.self_attn.v_proj.bias]   Loading weights:  14%|█▍        | 49/339 [00:00<00:00, 948.65it/s, Materializing param=model.layers.3.self_attn.v_proj.bias]Loading weights:  15%|█▍        | 50/339 [00:00<00:00, 954.98it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  15%|█▍        | 50/339 [00:00<00:00, 951.09it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  15%|█▌        | 51/339 [00:00<00:00, 955.29it/s, Materializing param=model.layers.4.input_layernorm.weight] Loading weights:  15%|█▌        | 51/339 [00:00<00:00, 951.50it/s, Materializing param=model.layers.4.input_layernorm.weight]Loading weights:  15%|█▌        | 52/339 [00:00<00:00, 954.16it/s, Materializing param=model.layers.4.mlp.down_proj.weight]  Loading weights:  15%|█▌        | 52/339 [00:00<00:00, 950.12it/s, Materializing param=model.layers.4.mlp.down_proj.weight]Loading weights:  16%|█▌        | 53/339 [00:00<00:00, 960.15it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  16%|█▌        | 53/339 [00:00<00:00, 957.24it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  16%|█▌        | 54/339 [00:00<00:00, 902.62it/s, Materializing param=model.layers.4.mlp.up_proj.weight]  Loading weights:  16%|█▌        | 54/339 [00:00<00:00, 899.41it/s, Materializing param=model.layers.4.mlp.up_proj.weight]Loading weights:  16%|█▌        | 55/339 [00:00<00:00, 906.24it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  16%|█▌        | 55/339 [00:00<00:00, 902.62it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  17%|█▋        | 56/339 [00:00<00:00, 907.62it/s, Materializing param=model.layers.4.self_attn.k_proj.bias]          Loading weights:  17%|█▋        | 56/339 [00:00<00:00, 904.07it/s, Materializing param=model.layers.4.self_attn.k_proj.bias]Loading weights:  17%|█▋        | 57/339 [00:00<00:00, 914.88it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]Loading weights:  17%|█▋        | 57/339 [00:00<00:00, 912.53it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]Loading weights:  17%|█▋        | 58/339 [00:00<00:00, 918.35it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  17%|█▋        | 58/339 [00:00<00:00, 914.91it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  17%|█▋        | 59/339 [00:00<00:00, 925.16it/s, Materializing param=model.layers.4.self_attn.q_proj.bias]  Loading weights:  17%|█▋        | 59/339 [00:00<00:00, 922.79it/s, Materializing param=model.layers.4.self_attn.q_proj.bias]Loading weights:  18%|█▊        | 60/339 [00:00<00:00, 927.59it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  18%|█▊        | 60/339 [00:00<00:00, 924.12it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  18%|█▊        | 61/339 [00:00<00:00, 930.36it/s, Materializing param=model.layers.4.self_attn.v_proj.bias]  Loading weights:  18%|█▊        | 61/339 [00:00<00:00, 926.52it/s, Materializing param=model.layers.4.self_attn.v_proj.bias]Loading weights:  18%|█▊        | 62/339 [00:00<00:00, 886.61it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  18%|█▊        | 62/339 [00:00<00:00, 883.53it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  19%|█▊        | 63/339 [00:00<00:00, 886.96it/s, Materializing param=model.layers.5.input_layernorm.weight] Loading weights:  19%|█▊        | 63/339 [00:00<00:00, 883.92it/s, Materializing param=model.layers.5.input_layernorm.weight]Loading weights:  19%|█▉        | 64/339 [00:00<00:00, 892.91it/s, Materializing param=model.layers.5.mlp.down_proj.weight]  Loading weights:  19%|█▉        | 64/339 [00:00<00:00, 890.65it/s, Materializing param=model.layers.5.mlp.down_proj.weight]Loading weights:  19%|█▉        | 65/339 [00:00<00:00, 895.90it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  19%|█▉        | 65/339 [00:00<00:00, 892.80it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  19%|█▉        | 66/339 [00:00<00:00, 882.75it/s, Materializing param=model.layers.5.mlp.up_proj.weight]  Loading weights:  19%|█▉        | 66/339 [00:00<00:00, 879.93it/s, Materializing param=model.layers.5.mlp.up_proj.weight]Loading weights:  20%|█▉        | 67/339 [00:00<00:00, 867.21it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  20%|█▉        | 67/339 [00:00<00:00, 864.43it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  20%|██        | 68/339 [00:00<00:00, 869.06it/s, Materializing param=model.layers.5.self_attn.k_proj.bias]          Loading weights:  20%|██        | 68/339 [00:00<00:00, 847.93it/s, Materializing param=model.layers.5.self_attn.k_proj.bias]Loading weights:  20%|██        | 69/339 [00:00<00:00, 831.37it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]Loading weights:  20%|██        | 69/339 [00:00<00:00, 828.94it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]Loading weights:  21%|██        | 70/339 [00:00<00:00, 833.01it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  21%|██        | 70/339 [00:00<00:00, 830.08it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  21%|██        | 71/339 [00:00<00:00, 834.64it/s, Materializing param=model.layers.5.self_attn.q_proj.bias]  Loading weights:  21%|██        | 71/339 [00:00<00:00, 832.31it/s, Materializing param=model.layers.5.self_attn.q_proj.bias]Loading weights:  21%|██        | 72/339 [00:00<00:00, 836.91it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  21%|██        | 72/339 [00:00<00:00, 834.58it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  22%|██▏       | 73/339 [00:00<00:00, 838.37it/s, Materializing param=model.layers.5.self_attn.v_proj.bias]  Loading weights:  22%|██▏       | 73/339 [00:00<00:00, 836.04it/s, Materializing param=model.layers.5.self_attn.v_proj.bias]Loading weights:  22%|██▏       | 74/339 [00:00<00:00, 814.63it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  22%|██▏       | 74/339 [00:00<00:00, 812.42it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  22%|██▏       | 75/339 [00:00<00:00, 813.79it/s, Materializing param=model.layers.6.input_layernorm.weight] Loading weights:  22%|██▏       | 75/339 [00:00<00:00, 811.58it/s, Materializing param=model.layers.6.input_layernorm.weight]Loading weights:  22%|██▏       | 76/339 [00:00<00:00, 815.81it/s, Materializing param=model.layers.6.mlp.down_proj.weight]  Loading weights:  22%|██▏       | 76/339 [00:00<00:00, 813.74it/s, Materializing param=model.layers.6.mlp.down_proj.weight]Loading weights:  23%|██▎       | 77/339 [00:00<00:00, 818.25it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  23%|██▎       | 77/339 [00:00<00:00, 816.20it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  23%|██▎       | 78/339 [00:00<00:00, 820.59it/s, Materializing param=model.layers.6.mlp.up_proj.weight]  Loading weights:  23%|██▎       | 78/339 [00:00<00:00, 818.56it/s, Materializing param=model.layers.6.mlp.up_proj.weight]Loading weights:  23%|██▎       | 79/339 [00:00<00:00, 820.51it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  23%|██▎       | 79/339 [00:00<00:00, 813.43it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  24%|██▎       | 80/339 [00:00<00:00, 818.41it/s, Materializing param=model.layers.6.self_attn.k_proj.bias]          Loading weights:  24%|██▎       | 80/339 [00:00<00:00, 816.81it/s, Materializing param=model.layers.6.self_attn.k_proj.bias]Loading weights:  24%|██▍       | 81/339 [00:00<00:00, 818.66it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]Loading weights:  24%|██▍       | 81/339 [00:00<00:00, 816.61it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]Loading weights:  24%|██▍       | 82/339 [00:00<00:00, 820.50it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  24%|██▍       | 82/339 [00:00<00:00, 818.51it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  24%|██▍       | 83/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  24%|██▍       | 83/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.q_proj.bias]  Loading weights:  24%|██▍       | 83/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.q_proj.bias]Loading weights:  25%|██▍       | 84/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  25%|██▍       | 84/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  25%|██▌       | 85/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.v_proj.bias]  Loading weights:  25%|██▌       | 85/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.v_proj.bias]Loading weights:  25%|██▌       | 86/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  25%|██▌       | 86/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  26%|██▌       | 87/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.input_layernorm.weight] Loading weights:  26%|██▌       | 87/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.input_layernorm.weight]Loading weights:  26%|██▌       | 88/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.mlp.down_proj.weight]  Loading weights:  26%|██▌       | 88/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.mlp.down_proj.weight]Loading weights:  26%|██▋       | 89/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  26%|██▋       | 89/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  27%|██▋       | 90/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.mlp.up_proj.weight]  Loading weights:  27%|██▋       | 90/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.mlp.up_proj.weight]Loading weights:  27%|██▋       | 91/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  27%|██▋       | 91/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  27%|██▋       | 92/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.k_proj.bias]          Loading weights:  27%|██▋       | 92/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.k_proj.bias]Loading weights:  27%|██▋       | 93/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]Loading weights:  27%|██▋       | 93/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]Loading weights:  28%|██▊       | 94/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  28%|██▊       | 94/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  28%|██▊       | 95/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.q_proj.bias]  Loading weights:  28%|██▊       | 95/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.q_proj.bias]Loading weights:  28%|██▊       | 96/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  28%|██▊       | 96/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  29%|██▊       | 97/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.v_proj.bias]  Loading weights:  29%|██▊       | 97/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.v_proj.bias]Loading weights:  29%|██▉       | 98/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  29%|██▉       | 98/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  29%|██▉       | 99/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.input_layernorm.weight] Loading weights:  29%|██▉       | 99/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.input_layernorm.weight]Loading weights:  29%|██▉       | 100/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.mlp.down_proj.weight] Loading weights:  29%|██▉       | 100/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.mlp.down_proj.weight]Loading weights:  30%|██▉       | 101/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  30%|██▉       | 101/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  30%|███       | 102/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.mlp.up_proj.weight]  Loading weights:  30%|███       | 102/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.mlp.up_proj.weight]Loading weights:  30%|███       | 103/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  30%|███       | 103/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  31%|███       | 104/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.k_proj.bias]          Loading weights:  31%|███       | 104/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.k_proj.bias]Loading weights:  31%|███       | 105/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]Loading weights:  31%|███       | 105/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]Loading weights:  31%|███▏      | 106/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  31%|███▏      | 106/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  32%|███▏      | 107/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.q_proj.bias]  Loading weights:  32%|███▏      | 107/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.q_proj.bias]Loading weights:  32%|███▏      | 108/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  32%|███▏      | 108/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  32%|███▏      | 109/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.v_proj.bias]  Loading weights:  32%|███▏      | 109/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.v_proj.bias]Loading weights:  32%|███▏      | 110/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  32%|███▏      | 110/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  33%|███▎      | 111/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.input_layernorm.weight] Loading weights:  33%|███▎      | 111/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.input_layernorm.weight]Loading weights:  33%|███▎      | 112/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.mlp.down_proj.weight]  Loading weights:  33%|███▎      | 112/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.mlp.down_proj.weight]Loading weights:  33%|███▎      | 113/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  33%|███▎      | 113/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  34%|███▎      | 114/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.mlp.up_proj.weight]  Loading weights:  34%|███▎      | 114/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.mlp.up_proj.weight]Loading weights:  34%|███▍      | 115/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  34%|███▍      | 115/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  34%|███▍      | 116/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.k_proj.bias]          Loading weights:  34%|███▍      | 116/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.k_proj.bias]Loading weights:  35%|███▍      | 117/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]Loading weights:  35%|███▍      | 117/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]Loading weights:  35%|███▍      | 118/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  35%|███▍      | 118/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  35%|███▌      | 119/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.q_proj.bias]  Loading weights:  35%|███▌      | 119/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.q_proj.bias]Loading weights:  35%|███▌      | 120/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  35%|███▌      | 120/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  36%|███▌      | 121/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.v_proj.bias]  Loading weights:  36%|███▌      | 121/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.v_proj.bias]Loading weights:  36%|███▌      | 122/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  36%|███▌      | 122/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  36%|███▋      | 123/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  36%|███▋      | 123/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  37%|███▋      | 124/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.mlp.down_proj.weight]  Loading weights:  37%|███▋      | 124/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.mlp.down_proj.weight]Loading weights:  37%|███▋      | 125/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  37%|███▋      | 125/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  37%|███▋      | 126/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.mlp.up_proj.weight]  Loading weights:  37%|███▋      | 126/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.mlp.up_proj.weight]Loading weights:  37%|███▋      | 127/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  37%|███▋      | 127/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  38%|███▊      | 128/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.k_proj.bias]          Loading weights:  38%|███▊      | 128/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.k_proj.bias]Loading weights:  38%|███▊      | 129/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]Loading weights:  38%|███▊      | 129/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]Loading weights:  38%|███▊      | 130/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  38%|███▊      | 130/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  39%|███▊      | 131/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.q_proj.bias]  Loading weights:  39%|███▊      | 131/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.q_proj.bias]Loading weights:  39%|███▉      | 132/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  39%|███▉      | 132/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  39%|███▉      | 133/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.v_proj.bias]  Loading weights:  39%|███▉      | 133/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.v_proj.bias]Loading weights:  40%|███▉      | 134/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  40%|███▉      | 134/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  40%|███▉      | 135/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.input_layernorm.weight] Loading weights:  40%|███▉      | 135/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.input_layernorm.weight]Loading weights:  40%|████      | 136/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.mlp.down_proj.weight]  Loading weights:  40%|████      | 136/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.mlp.down_proj.weight]Loading weights:  40%|████      | 137/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  40%|████      | 137/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  41%|████      | 138/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.mlp.up_proj.weight]  Loading weights:  41%|████      | 138/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.mlp.up_proj.weight]Loading weights:  41%|████      | 139/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  41%|████      | 139/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  41%|████▏     | 140/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.k_proj.bias]          Loading weights:  41%|████▏     | 140/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.k_proj.bias]Loading weights:  42%|████▏     | 141/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]Loading weights:  42%|████▏     | 141/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]Loading weights:  42%|████▏     | 142/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  42%|████▏     | 142/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  42%|████▏     | 143/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.q_proj.bias]  Loading weights:  42%|████▏     | 143/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.q_proj.bias]Loading weights:  42%|████▏     | 144/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  42%|████▏     | 144/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  43%|████▎     | 145/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.v_proj.bias]  Loading weights:  43%|████▎     | 145/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.v_proj.bias]Loading weights:  43%|████▎     | 146/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  43%|████▎     | 146/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  43%|████▎     | 147/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.input_layernorm.weight] Loading weights:  43%|████▎     | 147/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.input_layernorm.weight]Loading weights:  44%|████▎     | 148/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.mlp.down_proj.weight]  Loading weights:  44%|████▎     | 148/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.mlp.down_proj.weight]Loading weights:  44%|████▍     | 149/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  44%|████▍     | 149/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  44%|████▍     | 150/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.mlp.up_proj.weight]  Loading weights:  44%|████▍     | 150/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.mlp.up_proj.weight]Loading weights:  45%|████▍     | 151/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  45%|████▍     | 151/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  45%|████▍     | 152/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.k_proj.bias]          Loading weights:  45%|████▍     | 152/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.k_proj.bias]Loading weights:  45%|████▌     | 153/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]Loading weights:  45%|████▌     | 153/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]Loading weights:  45%|████▌     | 154/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  45%|████▌     | 154/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  46%|████▌     | 155/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.q_proj.bias]  Loading weights:  46%|████▌     | 155/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.q_proj.bias]Loading weights:  46%|████▌     | 156/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  46%|████▌     | 156/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  46%|████▋     | 157/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.v_proj.bias]  Loading weights:  46%|████▋     | 157/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.v_proj.bias]Loading weights:  47%|████▋     | 158/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  47%|████▋     | 158/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  47%|████▋     | 159/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.input_layernorm.weight] Loading weights:  47%|████▋     | 159/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.input_layernorm.weight]Loading weights:  47%|████▋     | 160/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.mlp.down_proj.weight]  Loading weights:  47%|████▋     | 160/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.mlp.down_proj.weight]Loading weights:  47%|████▋     | 161/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  47%|████▋     | 161/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  48%|████▊     | 162/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.mlp.up_proj.weight]  Loading weights:  48%|████▊     | 162/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.mlp.up_proj.weight]Loading weights:  48%|████▊     | 163/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  48%|████▊     | 163/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  48%|████▊     | 164/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.self_attn.k_proj.bias]          Loading weights:  48%|████▊     | 164/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.self_attn.k_proj.bias]Loading weights:  49%|████▊     | 165/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]Loading weights:  49%|████▊     | 165/339 [00:00<00:00, 823.29it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]Loading weights:  49%|████▉     | 166/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]Loading weights:  49%|████▉     | 166/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  49%|████▉     | 166/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  49%|████▉     | 167/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.q_proj.bias]  Loading weights:  49%|████▉     | 167/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.q_proj.bias]Loading weights:  50%|████▉     | 168/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  50%|████▉     | 168/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  50%|████▉     | 169/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.v_proj.bias]  Loading weights:  50%|████▉     | 169/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.v_proj.bias]Loading weights:  50%|█████     | 170/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  50%|█████     | 170/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  50%|█████     | 171/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.input_layernorm.weight] Loading weights:  50%|█████     | 171/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.input_layernorm.weight]Loading weights:  51%|█████     | 172/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.mlp.down_proj.weight]  Loading weights:  51%|█████     | 172/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.mlp.down_proj.weight]Loading weights:  51%|█████     | 173/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  51%|█████     | 173/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  51%|█████▏    | 174/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.mlp.up_proj.weight]  Loading weights:  51%|█████▏    | 174/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.mlp.up_proj.weight]Loading weights:  52%|█████▏    | 175/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  52%|█████▏    | 175/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  52%|█████▏    | 176/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.k_proj.bias]          Loading weights:  52%|█████▏    | 176/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.k_proj.bias]Loading weights:  52%|█████▏    | 177/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]Loading weights:  52%|█████▏    | 177/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]Loading weights:  53%|█████▎    | 178/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  53%|█████▎    | 178/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  53%|█████▎    | 179/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.q_proj.bias]  Loading weights:  53%|█████▎    | 179/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.q_proj.bias]Loading weights:  53%|█████▎    | 180/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  53%|█████▎    | 180/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  53%|█████▎    | 181/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.v_proj.bias]  Loading weights:  53%|█████▎    | 181/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.v_proj.bias]Loading weights:  54%|█████▎    | 182/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  54%|█████▎    | 182/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  54%|█████▍    | 183/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.input_layernorm.weight] Loading weights:  54%|█████▍    | 183/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.input_layernorm.weight]Loading weights:  54%|█████▍    | 184/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.mlp.down_proj.weight]  Loading weights:  54%|█████▍    | 184/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.mlp.down_proj.weight]Loading weights:  55%|█████▍    | 185/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  55%|█████▍    | 185/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  55%|█████▍    | 186/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.mlp.up_proj.weight]  Loading weights:  55%|█████▍    | 186/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.mlp.up_proj.weight]Loading weights:  55%|█████▌    | 187/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  55%|█████▌    | 187/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  55%|█████▌    | 188/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.k_proj.bias]          Loading weights:  55%|█████▌    | 188/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.k_proj.bias]Loading weights:  56%|█████▌    | 189/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]Loading weights:  56%|█████▌    | 189/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]Loading weights:  56%|█████▌    | 190/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  56%|█████▌    | 190/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  56%|█████▋    | 191/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.q_proj.bias]  Loading weights:  56%|█████▋    | 191/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.q_proj.bias]Loading weights:  57%|█████▋    | 192/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  57%|█████▋    | 192/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  57%|█████▋    | 193/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.v_proj.bias]  Loading weights:  57%|█████▋    | 193/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.v_proj.bias]Loading weights:  57%|█████▋    | 194/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  57%|█████▋    | 194/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  58%|█████▊    | 195/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.input_layernorm.weight] Loading weights:  58%|█████▊    | 195/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.input_layernorm.weight]Loading weights:  58%|█████▊    | 196/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.mlp.down_proj.weight]  Loading weights:  58%|█████▊    | 196/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.mlp.down_proj.weight]Loading weights:  58%|█████▊    | 197/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  58%|█████▊    | 197/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  58%|█████▊    | 198/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.mlp.up_proj.weight]  Loading weights:  58%|█████▊    | 198/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.mlp.up_proj.weight]Loading weights:  59%|█████▊    | 199/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  59%|█████▊    | 199/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  59%|█████▉    | 200/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.k_proj.bias]          Loading weights:  59%|█████▉    | 200/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.k_proj.bias]Loading weights:  59%|█████▉    | 201/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]Loading weights:  59%|█████▉    | 201/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]Loading weights:  60%|█████▉    | 202/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  60%|█████▉    | 202/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  60%|█████▉    | 203/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.q_proj.bias]  Loading weights:  60%|█████▉    | 203/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.q_proj.bias]Loading weights:  60%|██████    | 204/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  60%|██████    | 204/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  60%|██████    | 205/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.v_proj.bias]  Loading weights:  60%|██████    | 205/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.v_proj.bias]Loading weights:  61%|██████    | 206/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  61%|██████    | 206/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  61%|██████    | 207/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.input_layernorm.weight] Loading weights:  61%|██████    | 207/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.input_layernorm.weight]Loading weights:  61%|██████▏   | 208/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.mlp.down_proj.weight]  Loading weights:  61%|██████▏   | 208/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.mlp.down_proj.weight]Loading weights:  62%|██████▏   | 209/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  62%|██████▏   | 209/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  62%|██████▏   | 210/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.mlp.up_proj.weight]  Loading weights:  62%|██████▏   | 210/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.mlp.up_proj.weight]Loading weights:  62%|██████▏   | 211/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  62%|██████▏   | 211/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  63%|██████▎   | 212/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.k_proj.bias]          Loading weights:  63%|██████▎   | 212/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.k_proj.bias]Loading weights:  63%|██████▎   | 213/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]Loading weights:  63%|██████▎   | 213/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]Loading weights:  63%|██████▎   | 214/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  63%|██████▎   | 214/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  63%|██████▎   | 215/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.q_proj.bias]  Loading weights:  63%|██████▎   | 215/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.q_proj.bias]Loading weights:  64%|██████▎   | 216/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  64%|██████▎   | 216/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  64%|██████▍   | 217/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.v_proj.bias]  Loading weights:  64%|██████▍   | 217/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.v_proj.bias]Loading weights:  64%|██████▍   | 218/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  64%|██████▍   | 218/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  65%|██████▍   | 219/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.input_layernorm.weight] Loading weights:  65%|██████▍   | 219/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.input_layernorm.weight]Loading weights:  65%|██████▍   | 220/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.mlp.down_proj.weight]  Loading weights:  65%|██████▍   | 220/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.mlp.down_proj.weight]Loading weights:  65%|██████▌   | 221/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  65%|██████▌   | 221/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  65%|██████▌   | 222/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.mlp.up_proj.weight]  Loading weights:  65%|██████▌   | 222/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.mlp.up_proj.weight]Loading weights:  66%|██████▌   | 223/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  66%|██████▌   | 223/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  66%|██████▌   | 224/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.k_proj.bias]          Loading weights:  66%|██████▌   | 224/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.k_proj.bias]Loading weights:  66%|██████▋   | 225/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]Loading weights:  66%|██████▋   | 225/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]Loading weights:  67%|██████▋   | 226/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  67%|██████▋   | 226/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  67%|██████▋   | 227/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.q_proj.bias]  Loading weights:  67%|██████▋   | 227/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.q_proj.bias]Loading weights:  67%|██████▋   | 228/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  67%|██████▋   | 228/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  68%|██████▊   | 229/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.v_proj.bias]  Loading weights:  68%|██████▊   | 229/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.v_proj.bias]Loading weights:  68%|██████▊   | 230/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  68%|██████▊   | 230/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  68%|██████▊   | 231/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.input_layernorm.weight] Loading weights:  68%|██████▊   | 231/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.input_layernorm.weight]Loading weights:  68%|██████▊   | 232/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.mlp.down_proj.weight]  Loading weights:  68%|██████▊   | 232/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.mlp.down_proj.weight]Loading weights:  69%|██████▊   | 233/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  69%|██████▊   | 233/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  69%|██████▉   | 234/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.mlp.up_proj.weight]  Loading weights:  69%|██████▉   | 234/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.mlp.up_proj.weight]Loading weights:  69%|██████▉   | 235/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  69%|██████▉   | 235/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  70%|██████▉   | 236/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.self_attn.k_proj.bias]          Loading weights:  70%|██████▉   | 236/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.self_attn.k_proj.bias]Loading weights:  70%|██████▉   | 237/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]Loading weights:  70%|██████▉   | 237/339 [00:00<00:00, 707.25it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]Loading weights:  70%|███████   | 238/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]Loading weights:  70%|███████   | 238/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  70%|███████   | 238/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  71%|███████   | 239/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.q_proj.bias]  Loading weights:  71%|███████   | 239/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.q_proj.bias]Loading weights:  71%|███████   | 240/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  71%|███████   | 240/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  71%|███████   | 241/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.v_proj.bias]  Loading weights:  71%|███████   | 241/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.v_proj.bias]Loading weights:  71%|███████▏  | 242/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  71%|███████▏  | 242/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  72%|███████▏  | 243/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.input_layernorm.weight] Loading weights:  72%|███████▏  | 243/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.input_layernorm.weight]Loading weights:  72%|███████▏  | 244/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.mlp.down_proj.weight]  Loading weights:  72%|███████▏  | 244/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.mlp.down_proj.weight]Loading weights:  72%|███████▏  | 245/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  72%|███████▏  | 245/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  73%|███████▎  | 246/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.mlp.up_proj.weight]  Loading weights:  73%|███████▎  | 246/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.mlp.up_proj.weight]Loading weights:  73%|███████▎  | 247/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  73%|███████▎  | 247/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  73%|███████▎  | 248/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.k_proj.bias]          Loading weights:  73%|███████▎  | 248/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.k_proj.bias]Loading weights:  73%|███████▎  | 249/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]Loading weights:  73%|███████▎  | 249/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]Loading weights:  74%|███████▎  | 250/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  74%|███████▎  | 250/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  74%|███████▍  | 251/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.q_proj.bias]  Loading weights:  74%|███████▍  | 251/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.q_proj.bias]Loading weights:  74%|███████▍  | 252/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  74%|███████▍  | 252/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  75%|███████▍  | 253/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.v_proj.bias]  Loading weights:  75%|███████▍  | 253/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.v_proj.bias]Loading weights:  75%|███████▍  | 254/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  75%|███████▍  | 254/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  75%|███████▌  | 255/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.input_layernorm.weight] Loading weights:  75%|███████▌  | 255/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.input_layernorm.weight]Loading weights:  76%|███████▌  | 256/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.mlp.down_proj.weight]  Loading weights:  76%|███████▌  | 256/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.mlp.down_proj.weight]Loading weights:  76%|███████▌  | 257/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  76%|███████▌  | 257/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  76%|███████▌  | 258/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.mlp.up_proj.weight]  Loading weights:  76%|███████▌  | 258/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.mlp.up_proj.weight]Loading weights:  76%|███████▋  | 259/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  76%|███████▋  | 259/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  77%|███████▋  | 260/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.k_proj.bias]          Loading weights:  77%|███████▋  | 260/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.k_proj.bias]Loading weights:  77%|███████▋  | 261/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]Loading weights:  77%|███████▋  | 261/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]Loading weights:  77%|███████▋  | 262/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  77%|███████▋  | 262/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  78%|███████▊  | 263/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.q_proj.bias]  Loading weights:  78%|███████▊  | 263/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.q_proj.bias]Loading weights:  78%|███████▊  | 264/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights:  78%|███████▊  | 264/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights:  78%|███████▊  | 265/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.v_proj.bias]  Loading weights:  78%|███████▊  | 265/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.v_proj.bias]Loading weights:  78%|███████▊  | 266/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights:  78%|███████▊  | 266/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights:  79%|███████▉  | 267/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.input_layernorm.weight] Loading weights:  79%|███████▉  | 267/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.input_layernorm.weight]Loading weights:  79%|███████▉  | 268/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.mlp.down_proj.weight]  Loading weights:  79%|███████▉  | 268/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.mlp.down_proj.weight]Loading weights:  79%|███████▉  | 269/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.mlp.gate_proj.weight]Loading weights:  79%|███████▉  | 269/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.mlp.gate_proj.weight]Loading weights:  80%|███████▉  | 270/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.mlp.up_proj.weight]  Loading weights:  80%|███████▉  | 270/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.mlp.up_proj.weight]Loading weights:  80%|███████▉  | 271/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.post_attention_layernorm.weight]Loading weights:  80%|███████▉  | 271/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.post_attention_layernorm.weight]Loading weights:  80%|████████  | 272/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.k_proj.bias]          Loading weights:  80%|████████  | 272/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.k_proj.bias]Loading weights:  81%|████████  | 273/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.k_proj.weight]Loading weights:  81%|████████  | 273/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.k_proj.weight]Loading weights:  81%|████████  | 274/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.o_proj.weight]Loading weights:  81%|████████  | 274/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.o_proj.weight]Loading weights:  81%|████████  | 275/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.q_proj.bias]  Loading weights:  81%|████████  | 275/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.q_proj.bias]Loading weights:  81%|████████▏ | 276/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.q_proj.weight]Loading weights:  81%|████████▏ | 276/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.q_proj.weight]Loading weights:  82%|████████▏ | 277/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.v_proj.bias]  Loading weights:  82%|████████▏ | 277/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.v_proj.bias]Loading weights:  82%|████████▏ | 278/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.v_proj.weight]Loading weights:  82%|████████▏ | 278/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.22.self_attn.v_proj.weight]Loading weights:  82%|████████▏ | 279/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.input_layernorm.weight] Loading weights:  82%|████████▏ | 279/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.input_layernorm.weight]Loading weights:  83%|████████▎ | 280/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.mlp.down_proj.weight]  Loading weights:  83%|████████▎ | 280/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.mlp.down_proj.weight]Loading weights:  83%|████████▎ | 281/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.mlp.gate_proj.weight]Loading weights:  83%|████████▎ | 281/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.mlp.gate_proj.weight]Loading weights:  83%|████████▎ | 282/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.mlp.up_proj.weight]  Loading weights:  83%|████████▎ | 282/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.mlp.up_proj.weight]Loading weights:  83%|████████▎ | 283/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.post_attention_layernorm.weight]Loading weights:  83%|████████▎ | 283/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.post_attention_layernorm.weight]Loading weights:  84%|████████▍ | 284/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.k_proj.bias]          Loading weights:  84%|████████▍ | 284/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.k_proj.bias]Loading weights:  84%|████████▍ | 285/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.k_proj.weight]Loading weights:  84%|████████▍ | 285/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.k_proj.weight]Loading weights:  84%|████████▍ | 286/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.o_proj.weight]Loading weights:  84%|████████▍ | 286/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.o_proj.weight]Loading weights:  85%|████████▍ | 287/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.q_proj.bias]  Loading weights:  85%|████████▍ | 287/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.q_proj.bias]Loading weights:  85%|████████▍ | 288/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.q_proj.weight]Loading weights:  85%|████████▍ | 288/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.q_proj.weight]Loading weights:  85%|████████▌ | 289/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.v_proj.bias]  Loading weights:  85%|████████▌ | 289/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.v_proj.bias]Loading weights:  86%|████████▌ | 290/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.v_proj.weight]Loading weights:  86%|████████▌ | 290/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.23.self_attn.v_proj.weight]Loading weights:  86%|████████▌ | 291/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.input_layernorm.weight] Loading weights:  86%|████████▌ | 291/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.input_layernorm.weight]Loading weights:  86%|████████▌ | 292/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.mlp.down_proj.weight]  Loading weights:  86%|████████▌ | 292/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.mlp.down_proj.weight]Loading weights:  86%|████████▋ | 293/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.mlp.gate_proj.weight]Loading weights:  86%|████████▋ | 293/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.mlp.gate_proj.weight]Loading weights:  87%|████████▋ | 294/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.mlp.up_proj.weight]  Loading weights:  87%|████████▋ | 294/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.mlp.up_proj.weight]Loading weights:  87%|████████▋ | 295/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.post_attention_layernorm.weight]Loading weights:  87%|████████▋ | 295/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.post_attention_layernorm.weight]Loading weights:  87%|████████▋ | 296/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.k_proj.bias]          Loading weights:  87%|████████▋ | 296/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.k_proj.bias]Loading weights:  88%|████████▊ | 297/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.k_proj.weight]Loading weights:  88%|████████▊ | 297/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.k_proj.weight]Loading weights:  88%|████████▊ | 298/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.o_proj.weight]Loading weights:  88%|████████▊ | 298/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.o_proj.weight]Loading weights:  88%|████████▊ | 299/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.q_proj.bias]  Loading weights:  88%|████████▊ | 299/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.q_proj.bias]Loading weights:  88%|████████▊ | 300/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.q_proj.weight]Loading weights:  88%|████████▊ | 300/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.q_proj.weight]Loading weights:  89%|████████▉ | 301/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.v_proj.bias]  Loading weights:  89%|████████▉ | 301/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.v_proj.bias]Loading weights:  89%|████████▉ | 302/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.v_proj.weight]Loading weights:  89%|████████▉ | 302/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.24.self_attn.v_proj.weight]Loading weights:  89%|████████▉ | 303/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.input_layernorm.weight] Loading weights:  89%|████████▉ | 303/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.input_layernorm.weight]Loading weights:  90%|████████▉ | 304/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.mlp.down_proj.weight]  Loading weights:  90%|████████▉ | 304/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.mlp.down_proj.weight]Loading weights:  90%|████████▉ | 305/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.mlp.gate_proj.weight]Loading weights:  90%|████████▉ | 305/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.mlp.gate_proj.weight]Loading weights:  90%|█████████ | 306/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.mlp.up_proj.weight]  Loading weights:  90%|█████████ | 306/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.mlp.up_proj.weight]Loading weights:  91%|█████████ | 307/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.post_attention_layernorm.weight]Loading weights:  91%|█████████ | 307/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.post_attention_layernorm.weight]Loading weights:  91%|█████████ | 308/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.self_attn.k_proj.bias]          Loading weights:  91%|█████████ | 308/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.self_attn.k_proj.bias]Loading weights:  91%|█████████ | 309/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.self_attn.k_proj.weight]Loading weights:  91%|█████████ | 309/339 [00:00<00:00, 674.64it/s, Materializing param=model.layers.25.self_attn.k_proj.weight]Loading weights:  91%|█████████▏| 310/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.k_proj.weight]Loading weights:  91%|█████████▏| 310/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.o_proj.weight]Loading weights:  91%|█████████▏| 310/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.o_proj.weight]Loading weights:  92%|█████████▏| 311/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.q_proj.bias]  Loading weights:  92%|█████████▏| 311/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.q_proj.bias]Loading weights:  92%|█████████▏| 312/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.q_proj.weight]Loading weights:  92%|█████████▏| 312/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.q_proj.weight]Loading weights:  92%|█████████▏| 313/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.v_proj.bias]  Loading weights:  92%|█████████▏| 313/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.v_proj.bias]Loading weights:  93%|█████████▎| 314/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.v_proj.weight]Loading weights:  93%|█████████▎| 314/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.25.self_attn.v_proj.weight]Loading weights:  93%|█████████▎| 315/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.input_layernorm.weight] Loading weights:  93%|█████████▎| 315/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.input_layernorm.weight]Loading weights:  93%|█████████▎| 316/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.mlp.down_proj.weight]  Loading weights:  93%|█████████▎| 316/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.mlp.down_proj.weight]Loading weights:  94%|█████████▎| 317/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.mlp.gate_proj.weight]Loading weights:  94%|█████████▎| 317/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.mlp.gate_proj.weight]Loading weights:  94%|█████████▍| 318/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.mlp.up_proj.weight]  Loading weights:  94%|█████████▍| 318/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.mlp.up_proj.weight]Loading weights:  94%|█████████▍| 319/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.post_attention_layernorm.weight]Loading weights:  94%|█████████▍| 319/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.post_attention_layernorm.weight]Loading weights:  94%|█████████▍| 320/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.k_proj.bias]          Loading weights:  94%|█████████▍| 320/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.k_proj.bias]Loading weights:  95%|█████████▍| 321/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.k_proj.weight]Loading weights:  95%|█████████▍| 321/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.k_proj.weight]Loading weights:  95%|█████████▍| 322/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.o_proj.weight]Loading weights:  95%|█████████▍| 322/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.o_proj.weight]Loading weights:  95%|█████████▌| 323/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.q_proj.bias]  Loading weights:  95%|█████████▌| 323/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.q_proj.bias]Loading weights:  96%|█████████▌| 324/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.q_proj.weight]Loading weights:  96%|█████████▌| 324/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.q_proj.weight]Loading weights:  96%|█████████▌| 325/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.v_proj.bias]  Loading weights:  96%|█████████▌| 325/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.v_proj.bias]Loading weights:  96%|█████████▌| 326/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.v_proj.weight]Loading weights:  96%|█████████▌| 326/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.26.self_attn.v_proj.weight]Loading weights:  96%|█████████▋| 327/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.input_layernorm.weight] Loading weights:  96%|█████████▋| 327/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.input_layernorm.weight]Loading weights:  97%|█████████▋| 328/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.mlp.down_proj.weight]  Loading weights:  97%|█████████▋| 328/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.mlp.down_proj.weight]Loading weights:  97%|█████████▋| 329/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.mlp.gate_proj.weight]Loading weights:  97%|█████████▋| 329/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.mlp.gate_proj.weight]Loading weights:  97%|█████████▋| 330/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.mlp.up_proj.weight]  Loading weights:  97%|█████████▋| 330/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.mlp.up_proj.weight]Loading weights:  98%|█████████▊| 331/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.post_attention_layernorm.weight]Loading weights:  98%|█████████▊| 331/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.post_attention_layernorm.weight]Loading weights:  98%|█████████▊| 332/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.k_proj.bias]          Loading weights:  98%|█████████▊| 332/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.k_proj.bias]Loading weights:  98%|█████████▊| 333/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.k_proj.weight]Loading weights:  98%|█████████▊| 333/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.k_proj.weight]Loading weights:  99%|█████████▊| 334/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.o_proj.weight]Loading weights:  99%|█████████▊| 334/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.o_proj.weight]Loading weights:  99%|█████████▉| 335/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.q_proj.bias]  Loading weights:  99%|█████████▉| 335/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.q_proj.bias]Loading weights:  99%|█████████▉| 336/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.q_proj.weight]Loading weights:  99%|█████████▉| 336/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.q_proj.weight]Loading weights:  99%|█████████▉| 337/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.v_proj.bias]  Loading weights:  99%|█████████▉| 337/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.v_proj.bias]Loading weights: 100%|█████████▉| 338/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.v_proj.weight]Loading weights: 100%|█████████▉| 338/339 [00:00<00:00, 690.20it/s, Materializing param=model.layers.27.self_attn.v_proj.weight]Loading weights: 100%|██████████| 339/339 [00:00<00:00, 690.20it/s, Materializing param=model.norm.weight]                      Loading weights: 100%|██████████| 339/339 [00:00<00:00, 690.20it/s, Materializing param=model.norm.weight]Loading weights: 100%|██████████| 339/339 [00:00<00:00, 713.83it/s, Materializing param=model.norm.weight]
23:32:25  INFO      httpx  HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
23:32:25  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen2.5-7B-Instruct/a09a35458c702b33eeacc393d103063234e8bc28/generation_config.json "HTTP/1.1 200 OK"
23:32:25  INFO      httpx  HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
23:32:25  WARNING   huggingface_hub.utils._http  Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
23:32:28  INFO      src.evaluation.ablation  Base model loaded on cuda  dtype=bfloat16
23:32:28  INFO      src.evaluation.ablation  Config 'A_single_model' ready
23:32:28  INFO      src.evaluation.ablation  --- A_single_model / gsm8k ---
23:32:34  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
23:32:34  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/openai/gsm8k/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/README.md "HTTP/1.1 200 OK"
23:32:35  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/gsm8k.py "HTTP/1.1 404 Not Found"
23:32:35  INFO      httpx  HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/openai/gsm8k/openai/gsm8k.py "HTTP/1.1 404 Not Found"
23:32:35  INFO      httpx  HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/revision/cc7b047b6e5bb11b4f1af84efc572db110a51b3c "HTTP/1.1 200 OK"
23:32:35  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/.huggingface.yaml "HTTP/1.1 404 Not Found"
23:32:35  INFO      httpx  HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=openai/gsm8k "HTTP/1.1 200 OK"
23:32:36  INFO      httpx  HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/tree/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/main?recursive=true&expand=false "HTTP/1.1 200 OK"
23:32:36  INFO      httpx  HTTP Request: GET https://huggingface.co/api/datasets/openai/gsm8k/tree/cc7b047b6e5bb11b4f1af84efc572db110a51b3c?recursive=false&expand=false "HTTP/1.1 200 OK"
23:32:36  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/dataset_infos.json "HTTP/1.1 404 Not Found"
23:32:37  INFO      src.evaluation.benchmarks  Loaded 1319 examples from 'gsm8k'
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
23:35:12  INFO      src.evaluation.benchmarks  [gsm8k] DONE  accuracy=100.00% (10/10)  95%CI=[100.00%, 100.00%]
23:35:12  INFO      src.evaluation.ablation  ============================================================
23:35:12  INFO      src.evaluation.ablation  Setting up config: B_latentmas_nolora
23:35:12  INFO      src.evaluation.ablation  ============================================================
23:35:59  INFO      src.core.latent_reasoner  Realignment matrix built: torch.Size([3584, 3584])
23:36:08  INFO      src.system  System bootstrapped with first agent: Planner
23:36:09  INFO      src.evaluation.ablation  Config 'B_latentmas_nolora' ready
23:36:09  INFO      src.evaluation.ablation  --- B_latentmas_nolora / gsm8k ---
23:36:09  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
23:36:09  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/openai/gsm8k/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/README.md "HTTP/1.1 200 OK"
23:36:09  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/gsm8k.py "HTTP/1.1 404 Not Found"
23:36:09  INFO      httpx  HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/openai/gsm8k/openai/gsm8k.py "HTTP/1.1 404 Not Found"
23:36:10  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/.huggingface.yaml "HTTP/1.1 404 Not Found"
23:36:10  INFO      httpx  HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=openai/gsm8k "HTTP/1.1 200 OK"
23:36:10  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/dataset_infos.json "HTTP/1.1 404 Not Found"
23:36:10  INFO      src.evaluation.benchmarks  Loaded 1319 examples from 'gsm8k'
23:45:18  INFO      src.evaluation.benchmarks  [gsm8k] DONE  accuracy=60.00% (6/10)  95%CI=[30.00%, 90.00%]
23:45:18  INFO      src.evaluation.ablation  ============================================================
23:45:18  INFO      src.evaluation.ablation  Setting up config: C_latentmas_samelora
23:45:18  INFO      src.evaluation.ablation  ============================================================
/workspace/latent_mas_slora/venv/lib/python3.11/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
/workspace/latent_mas_slora/venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:285: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
23:45:42  INFO      src.core.latent_reasoner  Realignment matrix built: torch.Size([3584, 3584])
23:45:52  INFO      src.system  System bootstrapped with first agent: Planner
23:46:12  INFO      src.evaluation.ablation  Config 'C_latentmas_samelora' ready
23:46:12  INFO      src.evaluation.ablation  --- C_latentmas_samelora / gsm8k ---
23:46:12  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
23:46:12  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/openai/gsm8k/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/README.md "HTTP/1.1 200 OK"
23:46:13  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/gsm8k.py "HTTP/1.1 404 Not Found"
23:46:13  INFO      httpx  HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/openai/gsm8k/openai/gsm8k.py "HTTP/1.1 404 Not Found"
23:46:13  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/.huggingface.yaml "HTTP/1.1 404 Not Found"
23:46:13  INFO      httpx  HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=openai/gsm8k "HTTP/1.1 200 OK"
23:46:13  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/dataset_infos.json "HTTP/1.1 404 Not Found"
23:46:13  INFO      src.evaluation.benchmarks  Loaded 1319 examples from 'gsm8k'
23:56:50  INFO      src.evaluation.benchmarks  [gsm8k] DONE  accuracy=60.00% (6/10)  95%CI=[30.00%, 90.00%]
23:56:50  INFO      src.evaluation.ablation  ============================================================
23:56:50  INFO      src.evaluation.ablation  Setting up config: D_latentmas_speclora
23:56:50  INFO      src.evaluation.ablation  ============================================================
23:57:14  INFO      src.core.latent_reasoner  Realignment matrix built: torch.Size([3584, 3584])
23:57:22  INFO      src.system  System bootstrapped with first agent: Planner
23:57:42  INFO      src.evaluation.ablation  Config 'D_latentmas_speclora' ready
23:57:42  INFO      src.evaluation.ablation  --- D_latentmas_speclora / gsm8k ---
23:57:42  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
23:57:42  INFO      httpx  HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/openai/gsm8k/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/README.md "HTTP/1.1 200 OK"
23:57:42  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/gsm8k.py "HTTP/1.1 404 Not Found"
23:57:42  INFO      httpx  HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/openai/gsm8k/openai/gsm8k.py "HTTP/1.1 404 Not Found"
23:57:43  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/.huggingface.yaml "HTTP/1.1 404 Not Found"
23:57:43  INFO      httpx  HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=openai/gsm8k "HTTP/1.1 200 OK"
23:57:43  INFO      httpx  HTTP Request: HEAD https://huggingface.co/datasets/openai/gsm8k/resolve/cc7b047b6e5bb11b4f1af84efc572db110a51b3c/dataset_infos.json "HTTP/1.1 404 Not Found"
23:57:43  INFO      src.evaluation.benchmarks  Loaded 1319 examples from 'gsm8k'
00:08:02  INFO      src.evaluation.benchmarks  [gsm8k] DONE  accuracy=30.00% (3/10)  95%CI=[0.00%, 60.00%]
00:08:02  INFO      src.evaluation.statistical  D_latentmas_speclora vs B_latentmas_nolora: Δacc = -0.3000  p = 0.5595  (not significant at α=0.05)
00:08:02  INFO      src.evaluation.ablation  Ablation results saved → results/smoke_test/ablation_results.json
[INFO] Loaded adapter 'critic_lora': 2,523,136 trainable params
[INFO] Registered agent: Critic (role=critic, rank=1)
[INFO] Loaded adapter 'refiner_lora': 2,523,136 trainable params
[INFO] Registered agent: Refiner (role=refiner, rank=1)
[INFO] Loaded adapter 'judger_lora': 2,523,136 trainable params
[INFO] Registered agent: Judger (role=judger, rank=1)
[PLANNER] Generated 400 tokens in 17850ms
[CRITIC] Generated 350 tokens in 13413ms
[REFINER] Generated 426 tokens in 16174ms
[JUDGER] Generated 269 tokens in 10395ms
[PLANNER] Generated 339 tokens in 14638ms
[CRITIC] Generated 350 tokens in 13278ms
[REFINER] Generated 422 tokens in 16019ms
[JUDGER] Generated 205 tokens in 8021ms
[PLANNER] Generated 393 tokens in 16925ms
[CRITIC] Generated 350 tokens in 13306ms
[REFINER] Generated 450 tokens in 17079ms
[JUDGER] Generated 204 tokens in 7953ms
[PLANNER] Generated 386 tokens in 16748ms
[CRITIC] Generated 350 tokens in 13389ms
[REFINER] Generated 387 tokens in 14712ms
[JUDGER] Generated 247 tokens in 9545ms
[PLANNER] Generated 316 tokens in 13816ms
[CRITIC] Generated 350 tokens in 13227ms
[REFINER] Generated 382 tokens in 14404ms
[JUDGER] Generated 305 tokens in 11891ms
[PLANNER] Generated 348 tokens in 16296ms
[CRITIC] Generated 350 tokens in 13902ms
[REFINER] Generated 396 tokens in 14752ms
[JUDGER] Generated 286 tokens in 10877ms
[PLANNER] Generated 400 tokens in 17018ms
[CRITIC] Generated 350 tokens in 13323ms
[REFINER] Generated 337 tokens in 12862ms
[JUDGER] Generated 236 tokens in 9041ms
[PLANNER] Generated 400 tokens in 17137ms
[CRITIC] Generated 350 tokens in 13271ms
[REFINER] Generated 406 tokens in 15126ms
[JUDGER] Generated 239 tokens in 9177ms
[PLANNER] Generated 400 tokens in 17155ms
[CRITIC] Generated 350 tokens in 13250ms
[REFINER] Generated 450 tokens in 16913ms
[JUDGER] Generated 402 tokens in 14997ms
[PLANNER] Generated 400 tokens in 16730ms
[CRITIC] Generated 350 tokens in 12880ms
[REFINER] Generated 326 tokens in 12260ms
[JUDGER] Generated 194 tokens in 7661ms
[INFO] Loaded adapter 'critic_lora': 80,740,352 trainable params
[INFO] Registered agent: Critic (role=critic, rank=32)
[INFO] Loaded adapter 'refiner_lora': 121,110,528 trainable params
[INFO] Registered agent: Refiner (role=refiner, rank=48)
[INFO] Loaded adapter 'judger_lora': 161,480,704 trainable params
[INFO] Registered agent: Judger (role=judger, rank=64)
[PLANNER] Generated 400 tokens in 20138ms
[CRITIC] Generated 350 tokens in 15286ms
[REFINER] Generated 384 tokens in 16733ms
[JUDGER] Generated 236 tokens in 10548ms
[PLANNER] Generated 316 tokens in 15567ms
[CRITIC] Generated 350 tokens in 15545ms
[REFINER] Generated 381 tokens in 16754ms
[JUDGER] Generated 216 tokens in 9788ms
[PLANNER] Generated 400 tokens in 19584ms
[CRITIC] Generated 350 tokens in 15449ms
[REFINER] Generated 450 tokens in 19617ms
[JUDGER] Generated 314 tokens in 13966ms
[PLANNER] Generated 400 tokens in 19828ms
[CRITIC] Generated 350 tokens in 15537ms
[REFINER] Generated 251 tokens in 11178ms
[JUDGER] Generated 189 tokens in 8542ms
[PLANNER] Generated 398 tokens in 19601ms
[CRITIC] Generated 350 tokens in 15347ms
[REFINER] Generated 412 tokens in 18077ms
[JUDGER] Generated 273 tokens in 12016ms
[PLANNER] Generated 400 tokens in 19806ms
[CRITIC] Generated 350 tokens in 15490ms
[REFINER] Generated 369 tokens in 16281ms
[JUDGER] Generated 354 tokens in 15778ms
[PLANNER] Generated 400 tokens in 19580ms
[CRITIC] Generated 350 tokens in 15467ms
[REFINER] Generated 423 tokens in 18533ms
[JUDGER] Generated 319 tokens in 14185ms
[PLANNER] Generated 344 tokens in 17299ms
[CRITIC] Generated 350 tokens in 15321ms
[REFINER] Generated 450 tokens in 19590ms
[JUDGER] Generated 276 tokens in 12506ms
[PLANNER] Generated 400 tokens in 19640ms
[CRITIC] Generated 350 tokens in 15501ms
[REFINER] Generated 417 tokens in 18379ms
[JUDGER] Generated 293 tokens in 12939ms
[PLANNER] Generated 271 tokens in 13439ms
[CRITIC] Generated 350 tokens in 15364ms
[REFINER] Generated 450 tokens in 20090ms
[JUDGER] Generated 256 tokens in 11463ms
[INFO] Loaded adapter 'critic_lora': 80,740,352 trainable params
[INFO] Registered agent: Critic (role=critic, rank=32)
[INFO] Loaded adapter 'refiner_lora': 121,110,528 trainable params
[INFO] Registered agent: Refiner (role=refiner, rank=48)
[INFO] Loaded adapter 'judger_lora': 161,480,704 trainable params
[INFO] Registered agent: Judger (role=judger, rank=64)
[PLANNER] Generated 372 tokens in 20172ms
[CRITIC] Generated 350 tokens in 15710ms
[REFINER] Generated 321 tokens in 14233ms
[JUDGER] Generated 216 tokens in 9716ms
[PLANNER] Generated 290 tokens in 14272ms
[CRITIC] Generated 350 tokens in 15267ms
[REFINER] Generated 392 tokens in 17136ms
[JUDGER] Generated 254 tokens in 11350ms
[PLANNER] Generated 400 tokens in 19329ms
[CRITIC] Generated 350 tokens in 15330ms
[REFINER] Generated 425 tokens in 18294ms
[JUDGER] Generated 227 tokens in 9962ms
[PLANNER] Generated 365 tokens in 17819ms
[CRITIC] Generated 350 tokens in 15497ms
[REFINER] Generated 371 tokens in 16150ms
[JUDGER] Generated 223 tokens in 9991ms
[PLANNER] Generated 325 tokens in 16015ms
[CRITIC] Generated 350 tokens in 14945ms
[REFINER] Generated 355 tokens in 15132ms
[JUDGER] Generated 228 tokens in 10024ms
[PLANNER] Generated 400 tokens in 19216ms
[CRITIC] Generated 350 tokens in 15139ms
[REFINER] Generated 339 tokens in 14610ms
[JUDGER] Generated 288 tokens in 12777ms
[PLANNER] Generated 400 tokens in 19254ms
[CRITIC] Generated 350 tokens in 15049ms
[REFINER] Generated 450 tokens in 19333ms
[JUDGER] Generated 250 tokens in 10841ms
[PLANNER] Generated 400 tokens in 19428ms
[CRITIC] Generated 350 tokens in 15097ms
[REFINER] Generated 450 tokens in 19533ms
[JUDGER] Generated 284 tokens in 12661ms
[PLANNER] Generated 400 tokens in 19414ms
[CRITIC] Generated 350 tokens in 15207ms
[REFINER] Generated 412 tokens in 17559ms
[JUDGER] Generated 390 tokens in 16882ms
[PLANNER] Generated 313 tokens in 15275ms
[CRITIC] Generated 350 tokens in 14899ms
[REFINER] Generated 434 tokens in 18154ms
[JUDGER] Generated 282 tokens in 12127ms

Config                       Benchmark            Acc %           95% CI     Tok       ms
-----------------------------------------------------------------------------------------
A_single_model               gsm8k              100.00   [100.0, 100.0]   240.3    15565
B_latentmas_nolora           gsm8k               60.00     [30.0, 90.0]   257.7    54802
C_latentmas_samelora         gsm8k               60.00     [30.0, 90.0]   271.6    63640
D_latentmas_speclora         gsm8k               30.00      [0.0, 60.0]   263.2    61941

[SIG] gsm8k: D_latentmas_speclora vs B_latentmas_nolora: Δacc = -0.3000  p = 0.5595  (not significant at α=0.05)

================================================================
ABLATION COMPLETE
================================================================
Config                       Benchmark            Acc %           95% CI     Tok       ms
-----------------------------------------------------------------------------------------
A_single_model               gsm8k              100.00   [100.0, 100.0]   240.3    15565
B_latentmas_nolora           gsm8k               60.00     [30.0, 90.0]   257.7    54802
C_latentmas_samelora         gsm8k               60.00     [30.0, 90.0]   271.6    63640
D_latentmas_speclora         gsm8k               30.00      [0.0, 60.0]   263.2    61941

Wall time: 2140.1s

Statistical significance (B vs D):
  gsm8k: p=0.5595  ns  Δ=-0.3000

Results saved to: results/smoke_test/
